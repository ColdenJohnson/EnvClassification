{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Value Counts, 0 is not env, 1 is env: \n",
      "env\n",
      "0    20182\n",
      "1     7169\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# data import for 2005 data\n",
    "import pandas as pd\n",
    "\n",
    "data_2005 = pd.read_csv('/Users/colden/Documents/VSCode/Emos_Classification/Environment_Data_2005_cleaned.csv')\n",
    "\n",
    "data_2005['description'] = data_2005['name'] + ' ' + data_2005['mission'].fillna('')\n",
    "data_2005['data_year'] = 2005\n",
    "\n",
    "#data_2005 = data_2005.drop(data_2005[(data_2005['ntee1'] == 'S') & (data_2005['env'] == 0)].index) # drop all 'S' except for env = 1\n",
    "\n",
    "print('\\n\\n Value Counts, 0 is not env, 1 is env: ')\n",
    "print(data_2005['env'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Value Counts, 0 is not env, 1 is env: \n",
      "env\n",
      "0    21010\n",
      "1     4763\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# data import/cleaning for 2017/2018 data\n",
    "import pandas as pd\n",
    "\n",
    "file_path = '/Users/colden/Documents/VSCode/Emos_Classification/Environment_Data_2015_2016_cleaned.csv'\n",
    "data_2017 = pd.read_csv(file_path)\n",
    "data_2017['data_year'] = 2017\n",
    "\n",
    "# create ntee1 column\n",
    "data_2017['ntee1'] = data_2017['nteecc'].str[0]\n",
    "#data = data[data['ntee1'] != 'S']\n",
    "#data_2017 = data_2017.drop(data_2017[(data_2017['ntee1'] == 'S') & (data_2017['env'] == 0)].index) # drop all 'S' except for env = 1\n",
    "\n",
    "data_2017['mission'] = data_2017['mission'].str.replace('SEE SCHEDULE O', '')\n",
    "data_2017['description'] = data_2017['name'] + ' ' + data_2017['mission']\n",
    "\n",
    "\n",
    "print('\\n\\n Value Counts, 0 is not env, 1 is env: ')\n",
    "print(data_2017['env'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set data\n",
    "\n",
    "# drop a percent of a given ntee1 for 0 vals only\n",
    "def drop_perc_ntee1(data, ntee1, percent):\n",
    "    selected_rows = data[(data['ntee1'] == ntee1) & (data['env'] == 0)]\n",
    "    drop_rows = selected_rows.sample(frac=percent, random_state=1)\n",
    "    data_dropped = data.drop(drop_rows.index)\n",
    "    # print(data[data['ntee1'] == 'S']['env'].value_counts()) # prior to drop\n",
    "    # print(data_dropped[data_dropped['ntee1'] == 'S']['env'].value_counts()) # after drop\n",
    "    return data_dropped\n",
    "\n",
    "\n",
    "data = pd.concat([data_2005, data_2017], ignore_index=True)\n",
    "data = drop_perc_ntee1(data, 'S', 0.7)\n",
    "data.reset_index(drop=True, inplace=True) # this NEEDS to be called after drop_perc_ntee1!!! otherwise everything breaks (can't index later on with functions) # wow I'm slow\n",
    "data.insert(0, 'row_num', data.index)\n",
    "\n",
    "\n",
    "print(data['env'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import word_tokenize, pos_tag\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "data['description'] = data['description'].apply(lambda x: re.sub(r'[^\\w\\s]', '', str(x)))\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.add('s')\n",
    "stop_words.add('nan')\n",
    "\n",
    "\n",
    "# Remove stopwords from the description\n",
    "data['description'] = data['description'].apply(lambda x: ' '.join([word for word in str(x).split() if word.lower() not in stop_words]))\n",
    "\n",
    "# lematize function - taken from IBM: https://www.ibm.com/topics/stemming-lemmatization#:~:text=The%20practical%20distinction%20between%20stemming,be%20found%20in%20the%20dictionary.\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:         \n",
    "        return wordnet.NOUN\n",
    "\n",
    "def lemmatize_passage(text):\n",
    "    words = word_tokenize(text)\n",
    "    pos_tags = pos_tag(words)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_words = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "    lemmatized_sentence = ' '.join(lemmatized_words)\n",
    "    return lemmatized_sentence\n",
    "\n",
    "data['description'] = data['description'].apply(lemmatize_passage)\n",
    "print(\"/n/n Lemmatized Data: \")\n",
    "\n",
    "print(data['description'][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "confusion_matrix = pd.crosstab(data['ntee1'], data['env'])\n",
    "\n",
    "# Create a heatmap from the confusion matrix\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(confusion_matrix/len(data), annot=True, cmap='Blues', fmt='.2%')\n",
    "#sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "\n",
    "plt.title('NTEE Code and Environmental Organization')\n",
    "plt.xlabel('Environmental Organization')\n",
    "plt.ylabel('NTEE Code')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add NTEE codes to the description\n",
    "\n",
    "# def map_letters(letter):\n",
    "#     # if letter is not a, b, or c\n",
    "#     if letter not in ['c', 'b', 's', 'd']:\n",
    "#         return 'z'\n",
    "#     else:\n",
    "#         return letter\n",
    "        \n",
    "# data['description'] = data['description'] + ' ' + data['ntee1'].apply(map_letters) * 3\n",
    "\n",
    "\n",
    "# data['description'] = data['description'] + ' ' + data['ntee1'] * 3 # need to append 3 letters or the tokenizer won't work properly!!! so strange\n",
    "\n",
    "\n",
    "\n",
    "# map letters to numbers\n",
    "letter_to_num = {}\n",
    "\n",
    "# Iterate over each letter in the alphabet\n",
    "for i, letter in enumerate('ABCDEFGHIJKLMNOPQRSTUVWXYZ'):\n",
    "    # Add the letter to the dictionary with its corresponding number\n",
    "    letter_to_num[letter] = i + 1\n",
    "\n",
    "data['ntee_num'] = data['ntee1'].apply(lambda x: letter_to_num.get(x, 0))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put all of the cleaned data into a corpus\n",
    "# need to drop nan values\n",
    "corpus = []\n",
    "for i in range(len(data)):\n",
    "    row = data.iloc[i]\n",
    "    summary = row['description'].lower()\n",
    "    summary = summary.split()\n",
    "    clean_summary = ' '.join(summary)\n",
    "    corpus.append(clean_summary)\n",
    "    #print(row['env'])\n",
    "    \n",
    "\n",
    "corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "input_size = 1500 # number of words to keep -- note that this is also what is fed into the neural network as input size\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=input_size, min_df=3, max_df=0.8) #max features is number of words to keep, min_df is min # of documents a word must appear in, max_df is max percentage of documents a word can appear in\n",
    "X = vectorizer.fit_transform(corpus).toarray()\n",
    "\n",
    "y = data.loc[:, 'env'].values # env col\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# add in ntee codes (create dummies, then append these values to X)\n",
    "dummies = pd.get_dummies(data['ntee_num'], prefix = 'ntee')\n",
    "print(dummies)\n",
    "\n",
    "input_size += dummies.shape[1] # add the number of columns to the input size -- note that if this code block is run multiple times, must restart and run all\n",
    "X = np.concatenate((X, dummies), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "corpus_indices = np.arange(len(corpus))\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(X, y, corpus_indices, test_size=0.2, random_state=0)\n",
    "\n",
    "# How to print training data corresponding to corpus\n",
    "# print(idx_test[0]) # index of first test data\n",
    "# print(corpus[idx_test[0]]) # mechanism to print the first test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "X_test = torch.from_numpy(X_test).float()\n",
    "\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "y_test = torch.from_numpy(y_test).float()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "print(input_size) # number of words in the vectorized data\n",
    "output_size = 2 # binary classification -- maybe needs to be changed to get percentages?\n",
    "hidden_size = 500 # number of neurons in the hidden layer -- this should be tweaked\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "model = Net()\n",
    "\n",
    "import torch.optim as optim\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0005) # drop this down * 10^-1 more? increase epochs\n",
    "loss_fn = nn.NLLLoss() # CrossEntropyLoss() is the same as NLLLoss() with log_softmax ?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs =  100\n",
    "losses = []\n",
    "testing = []\n",
    "accuracy = None\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()\n",
    "    # Y_pred = model(X_train, ntee_train)\n",
    "    Y_pred = model(X_train)\n",
    "    loss = loss_fn(Y_pred, y_train.long())\n",
    "    losses.append(loss.detach().numpy())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch {epoch} / {epochs}, Loss: {loss.item()}')\n",
    "        print(f'Accuracy on test data at Epoch {epoch}: {accuracy}%')\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Assuming X_test is your test data and y_test are the true labels\n",
    "        Y_test_pred = model(X_test)\n",
    "        # Convert the predictions to class labels\n",
    "        _, predicted_labels = torch.max(Y_test_pred, 1)\n",
    "\n",
    "        # Calculate the number of correct predictions\n",
    "        correct_predictions = (predicted_labels == y_test).sum().item()\n",
    "        total_predictions = y_test.size(0)\n",
    "        accuracy = correct_predictions / total_predictions  # Accuracy as a percentage\n",
    "        testing.append(accuracy)\n",
    "\n",
    "    # Switch back to training mode\n",
    "    model.train()\n",
    "\n",
    "\n",
    "# (21880x1502 and 1500x500)\n",
    "# so, multiply with 1502 columns and 1502 rows is ok -- input_size vars will be the number of rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "# loss\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(epochs), losses, color = 'red')\n",
    "plt.ylabel(\"Loss/Error\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.title(\"Loss\")\n",
    "\n",
    "# accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(epochs), testing, color = \"blue\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.title(\"Accuracy\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "threshold = 0 # .5 change to 9/53 --> only 2 more identified, but many more cases # 0.2 seems to be pretty good\n",
    "\n",
    "false_neg_list, false_pos_list, correct_list, uncertain_list = [], [], [], []\n",
    "false_neg, false_pos, correct, uncertain = 0, 0, 0, 0\n",
    "y_predictions = []\n",
    "y_actual = []\n",
    "true_pos, true_neg = 0, 0 # sum to 'correct'\n",
    "\n",
    "with torch.no_grad():\n",
    "   for i, X_test_row in enumerate(X_test):\n",
    "      y_val = model.forward(X_test_row)\n",
    "      y_predictions.append(y_val)\n",
    "      predicted_class = y_val.argmax().item()\n",
    "      actual_class = y_test[i].item()\n",
    "      y_actual.append(actual_class)\n",
    "\n",
    "      if abs(y_val[0].item() - y_val[1].item()) < threshold:\n",
    "            print(f'{i+1}. {str(y_val)}, predicted {predicted_class}, actual {actual_class}')\n",
    "            uncertain_list.append(i)\n",
    "            uncertain += 1\n",
    "      elif predicted_class == actual_class:\n",
    "         correct_list.append(i)\n",
    "         correct += 1\n",
    "         if predicted_class == 0:\n",
    "            true_neg += 1\n",
    "         else:\n",
    "            true_pos += 1\n",
    "      elif predicted_class != actual_class:\n",
    "         if predicted_class == 0:\n",
    "            false_neg_list.append(i)\n",
    "            false_neg += 1\n",
    "         else:\n",
    "            false_pos_list.append(i)\n",
    "            false_pos += 1\n",
    "\n",
    "\n",
    "\n",
    "print(f'Correct: {correct}, False: {false_neg + false_pos}, Uncertain: {uncertain}')\n",
    "print(f'False prediction 0: {false_neg}, False prediction 1: {false_pos}')\n",
    "\n",
    "print(f'Accuracy: {(correct + uncertain) / (correct + false_neg + false_pos + uncertain)}')\n",
    "print(f'Precision: {true_pos / (true_pos + false_pos)}')\n",
    "print(f'Recall: {true_pos / (true_pos + false_neg)}')\n",
    "\n",
    "# currently, TfidfVectorizer is used to train the model. However, this is a bag of words model, which does not take into account the context of the words.\n",
    "# This is a limitation of the model. A better model might be a word2vec, BERT, FastText, Glove, etc. model, which takes into account the context of the words.\n",
    "# would also be nice to see which tensor goes with which word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions for the ntee model\n",
    "np.set_printoptions(threshold=500, linewidth=200, edgeitems=30)\n",
    "\n",
    "# given a test index, return the corresponding row in 'data'\n",
    "def get_from_testdata(position):\n",
    "    row = data.loc[idx_test[position]] # get the row in 'data' corresponding to the test index\n",
    "    return row\n",
    "\n",
    "# print(idx_test[0])\n",
    "# print(data.loc[20050])\n",
    "# get_datarow(0)\n",
    "# print()\n",
    "\n",
    "# input a row from 'data' to convert to tensor (with ntee codes)\n",
    "def predict_nteeincl(row_index):\n",
    "    input_text = vectorizer.transform([data['description'][row_index]]).toarray()\n",
    "    dummies_row = dummies.loc[row_index].values.reshape(1,-1) # reshape dummies list to 2d array \n",
    "    input_matrix = np.concatenate((input_text, dummies_row), axis = 1) # combine dummies (ntee) and input text\n",
    "    input_matrix = torch.from_numpy(input_matrix).float()\n",
    "    output = model(input_matrix)\n",
    "    return str(output) + ' , predicted:' + str(output.argmax().item())\n",
    "\n",
    "# print(predict_nteeincl(0)) # get prediction\n",
    "\n",
    "# pass in an array of indices, return the corresponding rows in 'data'\n",
    "def return_rows(array):\n",
    "    df_list = []\n",
    "    for test_i in array:\n",
    "        data_i = get_from_testdata(test_i)\n",
    "        df_list.append(data_i)\n",
    "    return_df = pd.concat(df_list, axis=1).transpose()\n",
    "    return return_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "directory = 'withNTEEoutputdirectory'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "return_rows(false_neg_list).to_csv(f'{directory}/false_neg.csv', index=False)\n",
    "return_rows(false_pos_list).to_csv(f'{directory}/false_pos.csv', index=False)\n",
    "return_rows(correct_list).to_csv(f'{directory}/correct.csv', index=False)\n",
    "try:\n",
    "    return_rows(uncertain_list).to_csv(f'{directory}/uncertain.csv', index=False)\n",
    "except ValueError:\n",
    "    print('No uncertain predictions')\n",
    "\n",
    "# create prediction_result column in 'data' to show prediction results\n",
    "def update_prediction_result(position_list, result):\n",
    "    for position in position_list:\n",
    "        index = idx_test[position]\n",
    "        data.loc[index, 'Prediction_Result'] = result\n",
    "\n",
    "update_prediction_result(correct_list, \"correct\")\n",
    "update_prediction_result(false_neg_list, \"false_neg\")\n",
    "update_prediction_result(false_pos_list, \"false_pos\")\n",
    "update_prediction_result(uncertain_list, \"uncertain\")\n",
    "\n",
    "data.to_csv(f'{directory}/final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = pd.crosstab(data['ntee1'], data['Prediction_Result'])\n",
    "\n",
    "# Create a heatmap from the confusion matrix\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(confusion_matrix/len(y_test), annot=True, cmap='Blues', fmt='.2%')\n",
    "# sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "\n",
    "plt.title('NTEE Code and Category Prediction (%)')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('NTEE Code')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "\n",
    "plt.title('NTEE Code and Category Prediction (Numeric)')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('NTEE Code')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.keys())\n",
    "\n",
    "confusion_matrix_predictedvactual = pd.crosstab(data['env'], data['Prediction_Result'])\n",
    "\n",
    "# Create a heatmap from the confusion matrix\n",
    "plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(confusion_matrix_predictedvactual, annot=True, cmap='Blues', fmt='g')\n",
    "# sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='g')\n",
    "\n",
    "plt.title('Predicted vs. Actual (NTEE model)')\n",
    "plt.xlabel('Prediction')\n",
    "plt.ylabel('Actual Value')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
